# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import datetime
import numpy as np
import os
import plpy
import sys
import time

# Do not remove `import keras` although it's not directly used in this file.
# For ex if the user passes in the optimizer as keras.optimizers.SGD instead of just
# SGD, then without this import this python file won't find the SGD module
import keras

from keras import backend as K
from keras import utils as keras_utils
from keras.layers import *
from keras.models import *
from keras.optimizers import *
from keras.regularizers import *
import madlib_keras_serializer
from madlib_keras_helper import MINIBATCH_OUTPUT_DEPENDENT_COLNAME_DL
from madlib_keras_helper import MINIBATCH_OUTPUT_INDEPENDENT_COLNAME_DL
from madlib_keras_helper import CLASS_VALUES_COLNAME
from madlib_keras_helper import DEPENDENT_VARTYPE_COLNAME
from madlib_keras_helper import NORMALIZING_CONST_COLNAME
from madlib_keras_validator import FitInputValidator
from madlib_keras_wrapper import *
from keras_model_arch_table import ModelArchSchema

from utilities.control import MinWarning
from utilities.model_arch_info import get_input_shape
from utilities.model_arch_info import get_num_classes
from utilities.utilities import _assert
from utilities.utilities import is_platform_pg
from utilities.utilities import get_segments_per_host
from utilities.utilities import madlib_version
from utilities.validate_args import get_col_value_and_type
from utilities.validate_args import get_expr_type
from utilities.validate_args import quote_ident

@MinWarning("warning")
def fit(schema_madlib, source_table, model,model_arch_table,
        model_arch_id, compile_params, fit_params, num_iterations,
        gpus_per_host = 0, validation_table=None,
        metrics_compute_frequency=None, name="",
        description="", **kwargs):
    source_table = quote_ident(source_table)
    dependent_varname = MINIBATCH_OUTPUT_DEPENDENT_COLNAME_DL
    independent_varname = MINIBATCH_OUTPUT_INDEPENDENT_COLNAME_DL
    model_arch_table = quote_ident(model_arch_table)
    fit_params = "" if not fit_params else fit_params
    _assert(compile_params, "Compile parameters cannot be empty or NULL.")

    fit_validator = FitInputValidator(
        source_table, validation_table, model, model_arch_table,
        dependent_varname, independent_varname,
        num_iterations, metrics_compute_frequency)
    if metrics_compute_frequency is None:
        metrics_compute_frequency = num_iterations

    # The following two times must be recorded together.
    metrics_elapsed_start_time = time.time()
    start_training_time = datetime.datetime.now()

    gpus_per_host = 0 if gpus_per_host is None else gpus_per_host
    segments_per_host = get_segments_per_host()

    if 0 < gpus_per_host < segments_per_host:
        plpy.warning('The number of gpus per host is less than the number of '
                     'segments per host. The support for this case is '
                     'experimental and it may fail.')

    #TODO add a unit test for this in a future PR
    # save the original value of the env variable so that we can reset it later.
    original_cuda_env = None
    if CUDA_VISIBLE_DEVICES_KEY in os.environ:
        original_cuda_env = os.environ[CUDA_VISIBLE_DEVICES_KEY]

    # Get the serialized master model
    start_deserialization = time.time()
    model_arch_query = "SELECT {0}, {1} FROM {2} WHERE {3} = {4}".format(
                                        ModelArchSchema.MODEL_ARCH, ModelArchSchema.MODEL_WEIGHTS,
                                        model_arch_table, ModelArchSchema.MODEL_ID,
                                        model_arch_id)
    model_arch_result = plpy.execute(model_arch_query)
    if not  model_arch_result:
        plpy.error("no model arch found in table {0} with id {1}".format(
            model_arch_table, model_arch_id))
    model_arch_result = model_arch_result[0]
    model_arch = model_arch_result[ModelArchSchema.MODEL_ARCH]
    input_shape = get_input_shape(model_arch)
    num_classes = get_num_classes(model_arch)
    fit_validator.validate_input_shapes(input_shape)
    model_weights_serialized = model_arch_result[ModelArchSchema.MODEL_WEIGHTS]

    #TODO: Refactor the pg related logic in a future PR when we think
    # about making the fit function easier to read and maintain.
    if is_platform_pg():
        gp_segment_id_col = '0'
        set_keras_session(gpus_per_host, segments_per_host)
    else:
        # we want to disable gpu on gpdb's master node because GPUs will only be used
        # for segment nodes.
        set_cuda_env('-1')
        gp_segment_id_col = 'gp_segment_id'

    # Compute total images on each segment
    seg_ids_train, images_per_seg_train = get_images_per_seg(source_table, dependent_varname)

    if validation_table:
        seg_ids_val, images_per_seg_val = get_images_per_seg(validation_table, dependent_varname)

    # Convert model from json and initialize weights
    master_model = model_from_json(model_arch)
    model_weights = master_model.get_weights()

    # Get shape of weights in each layer from model arch
    model_shapes = []
    for weight_arr in master_model.get_weights():
        model_shapes.append(weight_arr.shape)

    if model_weights_serialized:
        # If warm start from previously trained model, set weights
        model_weights = madlib_keras_serializer.deserialize_as_nd_weights(
            model_weights_serialized, model_shapes)
        master_model.set_weights(model_weights)

    # Construct validation dataset if provided
    validation_set_provided = bool(validation_table)
    validation_metrics = []; validation_loss = []

    # Prepare the SQL for running distributed training via UDA
    compile_params_to_pass = "$madlib$" + compile_params + "$madlib$"
    fit_params_to_pass = "$madlib$" + fit_params + "$madlib$"
    run_training_iteration = plpy.prepare("""
        SELECT {schema_madlib}.fit_step(
            {dependent_varname}::SMALLINT[],
            {independent_varname}::REAL[],
            $MAD${model_arch}$MAD$::TEXT,
            {compile_params_to_pass}::TEXT,
            {fit_params_to_pass}::TEXT,
            {gp_segment_id_col},
            ARRAY{seg_ids_train},
            ARRAY{images_per_seg_train},
            {gpus_per_host},
            {segments_per_host},
            $1
        ) AS iteration_result
        FROM {source_table}
        """.format(**locals()), ["bytea"])

    # Define the state for the model and loss/metric storage lists
    serialized_weights = madlib_keras_serializer.serialize_nd_weights(model_weights)
    training_loss, training_metrics, metrics_elapsed_time = [], [], []
    metrics_iters = []

    # get the size of serialized model weights string in KB
    model_size = sys.getsizeof(serialized_weights)/1024.0

    # Run distributed training for specified number of iterations
    for i in range(1, num_iterations+1):
        start_iteration = time.time()
        iteration_result = plpy.execute(run_training_iteration,
                                        [serialized_weights])[0]['iteration_result']
        end_iteration = time.time()
        plpy.info("Time for training in iteration {0}: {1} sec".
                  format(i, end_iteration - start_iteration))
        serialized_weights = madlib_keras_serializer.\
            get_serialized_1d_weights_from_state(iteration_result)

        if should_compute_metrics_this_iter(i, metrics_compute_frequency,
                                            num_iterations):
            # Compute loss/accuracy for training data.
            compute_loss_and_metrics(
                schema_madlib, source_table, dependent_varname,
                independent_varname, compile_params_to_pass, model_arch,
                serialized_weights, gpus_per_host, segments_per_host, seg_ids_train,
                images_per_seg_train, training_metrics, training_loss,
                i, "Training")
            metrics_iters.append(i)
            if validation_set_provided:
                # Compute loss/accuracy for validation data.
                compute_loss_and_metrics(
                    schema_madlib, validation_table, dependent_varname,
                    independent_varname, compile_params_to_pass, model_arch,
                    serialized_weights, gpus_per_host, segments_per_host, seg_ids_val,
                    images_per_seg_val, validation_metrics, validation_loss,
                    i, "Validation")
            metrics_elapsed_end_time = time.time()
            metrics_elapsed_time.append(
                metrics_elapsed_end_time-metrics_elapsed_start_time)

    end_training_time = datetime.datetime.now()

    version = madlib_version(schema_madlib)
    src_summary_dict = get_source_summary_table_dict(fit_validator)
    class_values = src_summary_dict['class_values']
    class_values_type = src_summary_dict['class_values_type']
    norm_const = src_summary_dict['norm_const']
    norm_const_type = src_summary_dict['norm_const_type']
    dep_vartype = src_summary_dict['dep_vartype']
    dependent_varname_in_source_table = src_summary_dict['dependent_varname_in_source_table']
    independent_varname_in_source_table = src_summary_dict['independent_varname_in_source_table']
    # Define some constants to be inserted into the summary table.
    model_type = "madlib_keras"
    compile_params_dict = convert_string_of_args_to_dict(compile_params)
    metrics_list = get_metrics_from_compile_param(compile_params)
    is_metrics_specified = True if metrics_list else False
    metrics_type = 'ARRAY{0}'.format(metrics_list) if is_metrics_specified else 'NULL'
    metrics_iters = metrics_iters if metrics_iters else 'NULL'
    # We always compute the training loss and metrics, at least once.
    training_loss_final = training_loss[-1]
    training_loss = 'ARRAY{0}'.format(training_loss) if training_loss else 'NULL'
    training_metrics_final, training_metrics = get_metrics_sql_string(
        training_metrics, is_metrics_specified)
    # Validation loss and metrics are computed only if validation_table
    # is provided.
    if validation_set_provided:
        validation_metrics_final, validation_metrics = get_metrics_sql_string(
            validation_metrics, is_metrics_specified)
        validation_loss_final = validation_loss[-1]
        validation_loss = 'ARRAY{0}'.format(validation_loss)
        # Must quote the string before inserting to table. Explicitly
        # quoting it here since this can also take a NULL value, done
        # in the else part.
        validation_table = "$MAD${0}$MAD$".format(validation_table)
    else:
        validation_metrics = validation_loss = 'NULL'
        validation_metrics_final = validation_loss_final = 'NULL'
        validation_table = 'NULL'

    create_output_summary_table = plpy.prepare("""
        CREATE TABLE {output_summary_model_table} AS
        SELECT
            $MAD${source_table}$MAD$::TEXT AS source_table,
            $MAD${model}$MAD$::TEXT AS model,
            $MAD${dependent_varname_in_source_table}$MAD$::TEXT AS dependent_varname,
            $MAD${independent_varname_in_source_table}$MAD$::TEXT AS independent_varname,
            $MAD${model_arch_table}$MAD$::TEXT AS model_arch_table,
            {model_arch_id}::INTEGER AS model_arch_id,
            $1 AS compile_params,
            $2 AS fit_params,
            {num_iterations}::INTEGER AS num_iterations,
            {validation_table}::TEXT AS validation_table,
            {metrics_compute_frequency}::INTEGER AS metrics_compute_frequency,
            $3 AS name,
            $4 AS description,
            '{model_type}'::TEXT AS model_type,
            {model_size}::DOUBLE PRECISION AS model_size,
            '{start_training_time}'::TIMESTAMP AS start_training_time,
            '{end_training_time}'::TIMESTAMP AS end_training_time,
            $5 AS metrics_elapsed_time,
            '{version}'::TEXT AS madlib_version,
            {num_classes}::INTEGER AS num_classes,
            $6 AS {class_values_colname},
            $MAD${dep_vartype}$MAD$::TEXT AS {dependent_vartype_colname},
            {norm_const}::DOUBLE PRECISION AS {normalizing_const_colname},
            {metrics_type}::TEXT[] AS metrics_type,
            {training_metrics_final}::DOUBLE PRECISION AS training_metrics_final,
            {training_loss_final}::DOUBLE PRECISION AS training_loss_final,
            {training_metrics}::DOUBLE PRECISION[] AS training_metrics,
            {training_loss}::DOUBLE PRECISION[] AS training_loss,
            {validation_metrics_final}::DOUBLE PRECISION AS validation_metrics_final,
            {validation_loss_final}::DOUBLE PRECISION AS validation_loss_final,
            {validation_metrics}::DOUBLE PRECISION[] AS validation_metrics,
            {validation_loss}::DOUBLE PRECISION[] AS validation_loss,
            ARRAY{metrics_iters}::INTEGER[] AS metrics_iters
        """.format(output_summary_model_table=fit_validator.output_summary_model_table,
                   class_values_colname=CLASS_VALUES_COLNAME,
                   dependent_vartype_colname=DEPENDENT_VARTYPE_COLNAME,
                   normalizing_const_colname=NORMALIZING_CONST_COLNAME,
                   **locals()),
                   ["TEXT", "TEXT", "TEXT","TEXT", "DOUBLE PRECISION[]",
                    class_values_type])
    plpy.execute(create_output_summary_table,
                 [compile_params, fit_params, name,
                  description, metrics_elapsed_time, class_values])

    create_output_table = plpy.prepare("""
        CREATE TABLE {0} AS SELECT
        $1 as model_data,
        $2 as {1}""".format(model, ModelArchSchema.MODEL_ARCH), ["bytea", "json"])
    plpy.execute(create_output_table, [serialized_weights, model_arch])

    if is_platform_pg():
        clear_keras_session()

    #TODO add a unit test for this in a future PR
    reset_cuda_env(original_cuda_env)

def get_source_summary_table_dict(fit_validator):
    source_summary = plpy.execute("""
            SELECT
                {class_values} AS class_values,
                {norm_const} AS norm_const,
                {dep_vartype} AS dep_vartype,
                {dep_varname} AS dependent_varname_in_source_table,
                {indep_varname} AS independent_varname_in_source_table
            FROM {tbl}
        """.format(class_values=CLASS_VALUES_COLNAME,
                   norm_const=NORMALIZING_CONST_COLNAME,
                   dep_vartype=DEPENDENT_VARTYPE_COLNAME,
                   dep_varname='dependent_varname',
                   indep_varname='independent_varname',
                   tbl=fit_validator.source_summary_table))[0]
    source_summary['class_values_type'] = get_expr_type(
        CLASS_VALUES_COLNAME, fit_validator.source_summary_table)
    source_summary['norm_const_type'] = get_expr_type(
        NORMALIZING_CONST_COLNAME, fit_validator.source_summary_table)
    return source_summary

def get_metrics_sql_string(metrics_list, is_metrics_specified):
    """
        Return the SQL string to use for creating metrics SQL values.
    """
    if is_metrics_specified:
        metrics_final = metrics_list[-1]
        metrics_all = 'ARRAY{0}'.format(metrics_list)
    else:
        metrics_final = metrics_all = 'NULL'
    return metrics_final, metrics_all

def compute_loss_and_metrics(schema_madlib, table, dependent_varname,
                             independent_varname, compile_params, model_arch,
                             serialized_weights, gpus_per_host, segments_per_host,
                             seg_ids, images_per_seg_val,
                             metrics_list, loss_list,
                             curr_iter, dataset_name):
    """
    Compute the loss and metric using a given model (serialized_weights) on the
    given dataset (table.)
    """
    start_val = time.time()
    evaluate_result = get_loss_metric_from_keras_eval(schema_madlib,
                                                   table,
                                                   dependent_varname,
                                                   independent_varname,
                                                   compile_params,
                                                   model_arch,
                                                   serialized_weights,
                                                   gpus_per_host,
                                                   segments_per_host,
                                                   seg_ids,
                                                   images_per_seg_val)
    end_val = time.time()
    plpy.info("Time for evaluation in iteration {0}: {1} sec.". format(
        curr_iter, end_val - start_val))
    if len(evaluate_result) not in [1, 2]:
        plpy.error('Calling evaluate on table {0} must return loss '
                   'and at most one metric value.'.format(
            table))
    loss = evaluate_result[0]
    metric = evaluate_result[1]
    plpy.info("{0} set metric after iteration {1}: {2}.".
              format(dataset_name, curr_iter, metric))
    plpy.info("{0} set loss after iteration {1}: {2}.".
              format(dataset_name, curr_iter, loss))
    metrics_list.append(metric)
    loss_list.append(loss)

def should_compute_metrics_this_iter(curr_iter, metrics_compute_frequency,
                                     num_iterations):
    """
    Check if we want to compute loss/accuracy for the current iteration
    :param curr_iter:
    :param metrics_compute_frequency:
    :param num_iterations:
    :return: Returns a boolean
            return TRUE, if it is the last iteration, or if metrics_compute_frequency
            iterations have elapsed since the last time it was computed.
            return FALSE otherwise.
    """
    # Compute loss/accuracy every metrics_compute_frequency'th iteration,
    # and also for the last iteration.
    return (curr_iter)%metrics_compute_frequency == 0 or \
           curr_iter == num_iterations

def get_images_per_seg(source_table, dependent_varname):
    """
    Compute total images in each segment, by querying source_table.  For
    postgres, this is just the total number of images in the db.
    :param source_table:
    :param dependent_var:
    :return: Returns a string and two arrays
    1. An array containing all the segment numbers in ascending order
    1. An array containing the total images on each of the segments in the
    segment array.
    """
    if is_platform_pg():
        res = plpy.execute(
            """ SELECT SUM(ARRAY_LENGTH({0}, 1)) AS images_per_seg
                FROM {1}
            """.format(dependent_varname, source_table))
        images_per_seg = [int(res[0]['images_per_seg'])]
        seg_ids = [0]
    else:
        images_per_seg = plpy.execute(
            """ SELECT gp_segment_id, SUM(ARRAY_LENGTH({0}, 1)) AS images_per_seg
                FROM {1}
                GROUP BY gp_segment_id
            """.format(dependent_varname, source_table))
        seg_ids = [int(each_segment["gp_segment_id"])
                   for each_segment in images_per_seg]
        images_per_seg = [int(each_segment["images_per_seg"])
            for each_segment in images_per_seg]
    return seg_ids, images_per_seg

def fit_transition(state, dependent_var, independent_var, model_architecture,
                   compile_params, fit_params, current_seg_id, seg_ids,
                   images_per_seg, gpus_per_host, segments_per_host,
                   prev_serialized_weights, **kwargs):
    if not independent_var or not dependent_var:
        return state

    start_transition = time.time()
    SD = kwargs['SD']
    device_name = get_device_name_and_set_cuda_env(gpus_per_host,
                                                   current_seg_id)
    # Set up system if this is the first buffer on segment'
    if not state:
        if not is_platform_pg():
            set_keras_session(gpus_per_host, segments_per_host)
        segment_model = model_from_json(model_architecture)
        compile_and_set_weights(segment_model, compile_params, device_name,
                                prev_serialized_weights)

        SD['segment_model'] = segment_model
        agg_image_count = 0
    else:
        segment_model = SD['segment_model']
        agg_image_count = madlib_keras_serializer.get_image_count_from_state(state)

    # Prepare the data
    x_train = np.array(independent_var, dtype='float64')
    y_train = np.array(dependent_var)

    # Fit segment model on data
    start_fit = time.time()
    with K.tf.device(device_name):
        #TODO consider not doing this every time
        fit_params = parse_and_validate_fit_params(fit_params)
        history = segment_model.fit(x_train, y_train, **fit_params)
    end_fit = time.time()

    image_count = len(x_train)
    # Aggregating number of images, loss and accuracy
    agg_image_count += image_count

    with K.tf.device(device_name):
        updated_weights = segment_model.get_weights()
    if is_platform_pg():
        total_images = images_per_seg[0]
    else:
        total_images = images_per_seg[seg_ids.index(current_seg_id)]

    if total_images == 0:
        plpy.error('Total images is 0 in fit_transition on segment {0}'.format(current_seg_id))

    # Re-serialize the weights
    # Update image count, check if we are done
    if agg_image_count == total_images:
       # Once done with all images on a segment, we update weights
        # with the total number of images here instead of the merge function.
        # The merge function only deals with aggregating them.
        updated_weights = [ total_images * w for w in updated_weights ]
        if not is_platform_pg():
            # In GPDB, each segment would have a keras session, so clear
            # them after the last buffer is processed.
            clear_keras_session()
    elif agg_image_count > total_images:
        plpy.error('Processed {0} images, but there were supposed to be only {1}!'
            .format(agg_image_count, total_images))

    new_state = madlib_keras_serializer.serialize_state_with_nd_weights(
        agg_image_count, updated_weights)

    del x_train
    del y_train

    end_transition = time.time()
    plpy.info("Processed {0} images: Fit took {1} sec, Total was {2} sec".format(
        image_count, end_fit - start_fit, end_transition - start_transition))

    return new_state

def fit_merge(state1, state2, **kwargs):

    # Return if called early
    if not state1 or not state2:
        return state1 or state2

    # Deserialize states
    image_count1, weights1 = madlib_keras_serializer.deserialize_as_image_1d_weights(state1)
    image_count2, weights2 = madlib_keras_serializer.deserialize_as_image_1d_weights(state2)

    # Compute total image counts
    image_count = (image_count1 + image_count2) * 1.0

    # Aggregate the weights
    total_weights = weights1 + weights2

    # Return the merged state
    return madlib_keras_serializer.serialize_state_with_1d_weights(
        image_count, total_weights)

def fit_final(state, **kwargs):
    # Return if called early
    if not state:
        return state

    image_count, weights = madlib_keras_serializer.deserialize_as_image_1d_weights(state)
    if image_count == 0:
        plpy.error("fit_final: Total images processed is 0")

    # Averaging the weights
    weights /= image_count
    return madlib_keras_serializer.serialize_state_with_1d_weights(
        image_count, weights)

def evaluate1(schema_madlib, model_table, test_table, id_col, model_arch_table,
            model_arch_id, dependent_varname, independent_varname,
            compile_params, output_table, **kwargs):
    # module_name = 'madlib_keras_evaluate'
    # input_tbl_valid(test_table, module_name)
    # input_tbl_valid(model_arch_table, module_name)
    # output_tbl_valid(output_table, module_name)

    # _validate_input_args(test_table, model_arch_table, output_table)

    model_data_query = "SELECT model_data from {0}".format(model_table)
    serialized_weights = plpy.execute(model_data_query)[0]['model_data']

    model_arch_query = "SELECT model_arch, model_weights FROM {0} " \
                       "WHERE id = {1}".format(model_arch_table, model_arch_id)
    query_result = plpy.execute(model_arch_query)
    if not  query_result or len(query_result) == 0:
        plpy.error("no model arch found in table {0} with id {1}".format(
            model_arch_table, model_arch_id))
    query_result = query_result[0]
    model_arch = query_result[ModelArchSchema.MODEL_ARCH]
    compile_params = "$madlib$" + compile_params + "$madlib$"

    loss_metric = get_loss_metric_from_keras_eval(
                    schema_madlib, test_table, dependent_varname,
                    independent_varname, compile_params, model_arch,
                    serialized_weights, False, None)

    #TODO remove these infos after adding create table command
    plpy.info('len of evaluate result is {}'.format(len(loss_metric)))
    plpy.info('evaluate result loss is {}'.format(loss_metric[0]))
    plpy.info('evaluate result metric is {}'.format(loss_metric[1]))

def get_loss_metric_from_keras_eval(schema_madlib, table, dependent_varname,
                                 independent_varname, compile_params,
                                 model_arch, serialized_weights, gpus_per_host,
                                 segments_per_host, seg_ids, images_per_seg):

    gp_segment_id_col = '0' if is_platform_pg() else 'gp_segment_id'

    """
    This function will call the internal keras evaluate function to get the loss
    and accuracy of each tuple which then gets averaged to get the final result.
    """
    evaluate_query = plpy.prepare("""
    -- TODO:  really, we should not be casting integers and big integers to smallint's
    --  The right solution is either to change the datatype of the agg function from
    --  SMALLINT to INTEGER, or change the output of minibatch util to produce SMALLINT
    --  For the first, we should change fit_step also
    select ({schema_madlib}.internal_keras_evaluate(
                                            {dependent_varname}::SMALLINT[],
                                            {independent_varname}::REAL[],
                                            $MAD${model_arch}$MAD$,
                                            $1,
                                            {compile_params},
                                            {gp_segment_id_col},
                                            ARRAY{seg_ids},
                                            ARRAY{images_per_seg},
                                            {gpus_per_host},
                                            {segments_per_host}
                                            )) as loss_metric
        from {table}
    """.format(**locals()), ["bytea"])
    res = plpy.execute(evaluate_query, [serialized_weights])
    loss_metric = res[0]['loss_metric']
    return loss_metric

def internal_keras_eval_transition(state, dependent_var, independent_var,
                                   model_architecture, serialized_weights, compile_params,
                                   current_seg_id, seg_ids, images_per_seg,
                                   gpus_per_host, segments_per_host, **kwargs):
    SD = kwargs['SD']
    device_name = get_device_name_and_set_cuda_env(gpus_per_host, current_seg_id)

    agg_loss, agg_metric, agg_image_count = state

    if not agg_image_count:
        if not is_platform_pg():
            set_keras_session(gpus_per_host, segments_per_host)
        model = model_from_json(model_architecture)
        compile_and_set_weights(model, compile_params, device_name,
                                serialized_weights)

        SD['segment_model'] = model
        # These should already be 0, but just in case make sure
        agg_metric = 0
        agg_loss = 0
    else:
        # Same model every time, no need to re-compile or update weights
        model = SD['segment_model']

    x_val = np.array(independent_var)
    y_val = np.array(dependent_var)

    with K.tf.device(device_name):
        res = model.evaluate(x_val, y_val)

    # if metric is None, model.evaluate will only return loss as a scalar
    # Otherwise, it will return a list which has loss and metric
    if type(res) is list:
        loss, metric = res
    else:
        loss = res
        metric = 0

    image_count = len(dependent_var)

    agg_image_count += image_count
    agg_loss += (image_count * loss)
    agg_metric += (image_count * metric)

    if is_platform_pg():
        total_images = images_per_seg[0]
    else:
        total_images = images_per_seg[seg_ids.index(current_seg_id)]

    if agg_image_count == total_images:
        SD.pop('segment_model', None)
        if not is_platform_pg():
            clear_keras_session()
    elif agg_image_count > total_images:
        plpy.error("Evaluated too many images.")

    state[0] = agg_loss
    state[1] = agg_metric
    state[2] = agg_image_count

    return state

def internal_keras_eval_merge(state1, state2, **kwargs):
    # If either state is None, return the other one
    if not state1 or not state2:
        return state1 or state2

    loss1, metric1, image_count1 = state1
    loss2, metric2, image_count2 = state2

    merged_loss = loss1 + loss2
    merged_metric = metric1 + metric2
    total_image_count = image_count1 + image_count2

    merged_state = [ merged_loss, merged_metric , total_image_count ]

    return merged_state

def internal_keras_eval_final(state, **kwargs):
    loss, metric, image_count = state

    if image_count == 0:
        plpy.error("internal_keras_eval_final: Total images processed is 0")

    loss /= image_count
    metric /= image_count

    state = loss, metric
    return state
